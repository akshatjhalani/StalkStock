{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "model_package_group_name = f\"StalkStockModelPackageGroupName\"\n",
    "\n",
    "CONTEXT_LENGTH = 191\n",
    "PREDICTION_LENGTH = 7\n",
    "\n",
    "BUCKET = \"sagemaker-stock-prices\"\n",
    "s3_data_path = f\"{BUCKET}/data\"\n",
    "s3_evaluate_result_path = f\"{BUCKET}/result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.c5.2xlarge\"\n",
    ")\n",
    "# model_approval_status = ParameterString(\n",
    "#     name=\"ModelApprovalStatus\",\n",
    "#     default_value=\"PendingManualApproval\"\n",
    "# )\n",
    "# input_data = ParameterString(\n",
    "#     name=\"InputData\",\n",
    "#     default_value=input_data_uri,\n",
    "# )\n",
    "# batch_data = ParameterString(\n",
    "#     name=\"BatchData\",\n",
    "#     default_value=batch_data_uri,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stalk-stock/processing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stalk-stock/processing.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "# predict for 7 days\n",
    "PREDICTION_LENGTH = 7\n",
    "\n",
    "BUCKET = \"sagemaker-stock-prices\"\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET)\n",
    "\n",
    "macd_hists = []\n",
    "\n",
    "\n",
    "def get_macd(data):\n",
    "    exp1 = data.ewm(span=12, adjust=False).mean()\n",
    "    exp2 = data.ewm(span=26, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "    return macd\n",
    "\n",
    "    \n",
    "def series_to_obj(ts, cat=None):\n",
    "    import math\n",
    "    obj = {\"start\": f\"{ts.index[0]} 00:00:00\", \"target\": [None if math.isnan(t) else t for t in ts]}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "\n",
    "def series_to_jsonline(ts, cat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    idx = 0\n",
    "    for obj in bucket.objects.filter(Prefix=\"raw/\"):\n",
    "        key = obj.key\n",
    "        print(key)\n",
    "        symbol = os.path.basename(key).split('.')[0]\n",
    "\n",
    "        table = pd.read_csv(io.BytesIO(obj.get()['Body'].read()), index_col=0, parse_dates=True)\n",
    "        table = table['Close']\n",
    "\n",
    "        macd = get_macd(table)\n",
    "        exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "        macd_hist = macd - exp3\n",
    "        macd_hist = macd_hist.asfreq('D')\n",
    "        macd_hists.append(macd_hist)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(macd_hist)\n",
    "\n",
    "        idx += 1\n",
    "    \n",
    "    macd_hists_training = []\n",
    "    for h in macd_hists:\n",
    "        macd_hists_training.append(h[:-PREDICTION_LENGTH])\n",
    "        \n",
    "    print(series_to_jsonline(macd_hists[0]).encode(\"utf-8\"))\n",
    "    \n",
    "    encoding = \"utf-8\"\n",
    "    FILE_TRAIN = \"train.json\"\n",
    "    FILE_TEST = \"test.json\"\n",
    "    BASE_DIR = \"/opt/ml/processing\"\n",
    "    if not os.path.exists(BASE_DIR):\n",
    "        os.mkdir(BASE_DIR)\n",
    "    if not os.path.exists(f\"{BASE_DIR}/train\"):\n",
    "        os.mkdir(f\"{BASE_DIR}/train\")\n",
    "    if not os.path.exists(f\"{BASE_DIR}/test\"):\n",
    "        os.mkdir(f\"{BASE_DIR}/test\")  \n",
    "        \n",
    "    with open(f\"{BASE_DIR}/train/{FILE_TRAIN}\", \"wb\") as f:\n",
    "        for ts in macd_hists_training:\n",
    "            f.write(series_to_jsonline(ts).encode(encoding))\n",
    "            f.write(\"\\n\".encode(encoding))\n",
    "\n",
    "    with open(f\"{BASE_DIR}/test/{FILE_TEST}\", \"wb\") as f:\n",
    "        for ts in macd_hists:\n",
    "            f.write(series_to_jsonline(ts).encode(encoding))\n",
    "            f.write(\"\\n\".encode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "# processing_image_uri = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, version=\"1.0-1\")\n",
    "script_process = ScriptProcessor(\n",
    "    image_uri=\"555178539686.dkr.ecr.us-east-1.amazonaws.com/stalk-stock-processor:latest\",\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-stalkstock-processing\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"StalkStockProcess\",\n",
    "    processor=script_process,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", destination=f\"s3://{s3_data_path}/train/\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test\", destination=f\"s3://{s3_data_path}/test/\", source=\"/opt/ml/processing/test\")\n",
    "    ],\n",
    "    code=\"stalk-stock/processing.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"forecasting-deepar\", boto3.Session().region_name)\n",
    "s3_model_path = f\"{BUCKET}/output\"\n",
    "\n",
    "deepar_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    output_path=f\"s3://{s3_model_path}\",\n",
    ")\n",
    "\n",
    "# hyperparameters = {\n",
    "#     \"time_freq\": \"D\",\n",
    "#     \"context_length\": str(CONTEXT_LENGTH),\n",
    "#     \"prediction_length\": str(PREDICTION_LENGTH),\n",
    "#     \"embedding_dimension\": \"49\",\n",
    "#     \"num_cells\": \"181\",\n",
    "#     \"num_layers\": \"4\",\n",
    "#     \"likelihood\": \"gaussian\",\n",
    "#     \"epochs\": \"100\",\n",
    "#     \"mini_batch_size\": \"200\",\n",
    "#     \"learning_rate\": \"0.000102117271092181\",\n",
    "#     \"dropout_rate\": \"0.07290734463384366\",\n",
    "#     \"early_stopping_patience\": \"10\",\n",
    "# }\n",
    "hyperparameters = {\n",
    "    \"time_freq\": \"D\",\n",
    "    \"context_length\": str(CONTEXT_LENGTH),\n",
    "    \"prediction_length\": str(PREDICTION_LENGTH),\n",
    "    \"embedding_dimension\": \"21\",\n",
    "    \"num_cells\": \"180\",\n",
    "    \"num_layers\": \"2\",\n",
    "    \"likelihood\": \"gaussian\",\n",
    "    \"epochs\": \"40\",\n",
    "    \"mini_batch_size\": \"171\",\n",
    "    \"learning_rate\": \"0.00017010544816687748\",\n",
    "    \"dropout_rate\": \"0.17607352219111227\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "}\n",
    "deepar_train.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"StalkStockTrain\",\n",
    "    estimator=deepar_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting stalk-stock/evaluating.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile stalk-stock/evaluating.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import io\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "\n",
    "def series_to_obj(ts, cat=None):\n",
    "    import math\n",
    "    obj = {\"start\": f\"{ts.index[0]} 00:00:00\", \"target\": [None if math.isnan(t) else t for t in ts]}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    return obj\n",
    "\n",
    "\n",
    "def series_to_jsonline(ts, cat=None):\n",
    "    return json.dumps(series_to_obj(ts, cat))\n",
    "\n",
    "\n",
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    def set_prediction_parameters(self, freq, prediction_length):\n",
    "        \"\"\"Set the time frequency and prediction length parameters. This method **must** be called\n",
    "        before being able to use `predict`.\n",
    "\n",
    "        Parameters:\n",
    "        freq -- string indicating the time frequency\n",
    "        prediction_length -- integer, number of predicted time points\n",
    "\n",
    "        Return value: none.\n",
    "        \"\"\"\n",
    "        self.freq = freq\n",
    "        self.prediction_length = prediction_length\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            ts,\n",
    "            cat=None,\n",
    "            encoding=\"utf-8\",\n",
    "            num_samples=100,\n",
    "            quantiles=[\"0.1\", \"0.5\", \"0.9\"],\n",
    "            content_type=\"application/json\",\n",
    "    ):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "\n",
    "        Parameters:\n",
    "        ts -- list of `pandas.Series` objects, the time series to predict\n",
    "        cat -- list of integers (default: None)\n",
    "        encoding -- string, encoding to use for the request (default: \"utf-8\")\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "\n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_times = [x.index[-1] + pd.Timedelta(1, unit=self.freq) for x in ts]\n",
    "        req = self.__encode_request(ts, cat, encoding, num_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req, initial_args={\"ContentType\": content_type})\n",
    "        return self.__decode_response(res, prediction_times, encoding)\n",
    "\n",
    "    def __encode_request(self, ts, cat, encoding, num_samples, quantiles):\n",
    "        instances = [series_to_obj(ts[k], cat[k] if cat else None) for k in range(len(ts))]\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\"],\n",
    "            \"quantiles\": quantiles,\n",
    "        }\n",
    "        http_request_data = {\"instances\": instances, \"configuration\": configuration}\n",
    "        return json.dumps(http_request_data).encode(encoding)\n",
    "\n",
    "    def __decode_response(self, response, prediction_times, encoding):\n",
    "        response_data = json.loads(response.decode(encoding))\n",
    "        list_of_df = []\n",
    "        for k in range(len(prediction_times)):\n",
    "            prediction_index = pd.date_range(\n",
    "                start=prediction_times[k], freq=self.freq, periods=self.prediction_length\n",
    "            )\n",
    "            list_of_df.append(\n",
    "                pd.DataFrame(\n",
    "                    data=response_data[\"predictions\"][k][\"quantiles\"], index=prediction_index\n",
    "                )\n",
    "            )\n",
    "        return list_of_df\n",
    "\n",
    "\n",
    "def macd_hist_to_price(stock_prices, macd_hist):\n",
    "    dt = macd_hist.index[0] - datetime.timedelta(days=1)\n",
    "    stock_prices = stock_prices.loc[:dt]\n",
    "    #     print(macd_hist)\n",
    "    #     print(stock_prices)\n",
    "    for dt, m in macd_hist.items():\n",
    "        stock_prices = binary_search(stock_prices, dt, m)\n",
    "    return stock_prices\n",
    "\n",
    "\n",
    "def get_macd(data):\n",
    "    exp1 = data.ewm(span=12, adjust=False).mean()\n",
    "    exp2 = data.ewm(span=26, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "    return macd\n",
    "\n",
    "\n",
    "def binary_search(prices, dt, m):\n",
    "    low = 0.0\n",
    "    high = prices.iloc[-1] * 2.0\n",
    "    cnt = 0\n",
    "    while cnt < 1000:\n",
    "        mid = low + (high - low) / 2\n",
    "        new_prices = pd.concat([prices, pd.Series([mid], index=[dt])])\n",
    "        macd = get_macd(new_prices)\n",
    "        exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "        macd_hist = macd - exp3\n",
    "        #         print(f\"low={low}, high={high}, mid={mid}\")\n",
    "        #         print(f\"loss={math.fabs(m - macd_hist.iloc[-1])}\")\n",
    "        if math.fabs(m - macd_hist.iloc[-1]) < 1e-10:\n",
    "            break\n",
    "        elif m < macd_hist.iloc[-1]:\n",
    "            high = mid\n",
    "        elif m > macd_hist.iloc[-1]:\n",
    "            low = mid\n",
    "    return new_prices\n",
    "\n",
    "\n",
    "macd_hists = []\n",
    "stock_prices = []\n",
    "symbol_names = []\n",
    "\n",
    "PREDICTION_LENGTH = 7\n",
    "\n",
    "boto3_session = boto3.Session(\n",
    "    aws_access_key_id=\"AKIAYCQZYHKTIPZ2WF6V\",\n",
    "    aws_secret_access_key=\"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\",\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3_session)\n",
    "# role = sagemaker_session.get_execution_role()\n",
    "# print(role)\n",
    "\n",
    "BUCKET = \"sagemaker-stock-prices\"\n",
    "s3 = boto3_session.resource('s3')\n",
    "\n",
    "bucket = s3.Bucket(BUCKET)\n",
    "\n",
    "for obj in bucket.objects.filter(Prefix=\"raw/\"):\n",
    "    key = obj.key\n",
    "    print(key)\n",
    "    symbol = os.path.basename(key).split('.')[0]\n",
    "\n",
    "    table = pd.read_csv(io.BytesIO(obj.get()['Body'].read()), index_col=0, parse_dates=True)\n",
    "    table = table['Close']\n",
    "    stock_prices.append(table)\n",
    "    symbol_names.append(symbol)\n",
    "\n",
    "    macd = get_macd(table)\n",
    "    exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "    macd_hist = macd - exp3\n",
    "    macd_hist = macd_hist.asfreq('D')\n",
    "    macd_hists.append(macd_hist)\n",
    "\n",
    "sm = boto3_session.client('sagemaker')\n",
    "response = sm.list_training_jobs(\n",
    "    MaxResults=10,\n",
    "    NameContains='StalkStockTrain',\n",
    "    StatusEquals='Completed',\n",
    "    SortBy='CreationTime',\n",
    "    SortOrder='Descending',\n",
    ")\n",
    "# print(response)\n",
    "job_name = response[\"TrainingJobSummaries\"][0][\"TrainingJobName\"]\n",
    "print(job_name)\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\"forecasting-deepar\", boto3_session.region_name)\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    image_uri=image_uri,\n",
    "    # role=role,\n",
    ")\n",
    "\n",
    "predictor = DeepARPredictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)\n",
    "predictor.set_prediction_parameters(\"D\", PREDICTION_LENGTH)\n",
    "\n",
    "list_of_df = predictor.predict(macd_hists, content_type=\"application/json\")\n",
    "\n",
    "# remove weekend\n",
    "for k in range(len(list_of_df)):\n",
    "    s = list_of_df[k]\n",
    "    list_of_df[k] = s[s.index.dayofweek < 5]\n",
    "\n",
    "predict_prices = []\n",
    "for k in range(len(list_of_df)):\n",
    "    predict_prices.append(pd.DataFrame({\n",
    "        \"0.1\": macd_hist_to_price(stock_prices[k], list_of_df[k][\"0.1\"]),\n",
    "        \"0.5\": macd_hist_to_price(stock_prices[k], list_of_df[k][\"0.5\"]),\n",
    "        \"0.9\": macd_hist_to_price(stock_prices[k], list_of_df[k][\"0.9\"])\n",
    "    }))\n",
    "\n",
    "encoding = \"utf-8\"\n",
    "BASE_DIR = \"/opt/ml/processing\"\n",
    "\n",
    "if not os.path.exists(BASE_DIR):\n",
    "    os.mkdir(BASE_DIR)\n",
    "if not os.path.exists(f\"{BASE_DIR}/macd\"):\n",
    "    os.mkdir(f\"{BASE_DIR}/macd\")\n",
    "if not os.path.exists(f\"{BASE_DIR}/price\"):\n",
    "    os.mkdir(f\"{BASE_DIR}/price\")\n",
    "\n",
    "for k in range(len(symbol_names)):\n",
    "    list_of_df[k].to_csv(f\"{BASE_DIR}/macd/{symbol_names[k]}.csv\")\n",
    "    predict_prices[k].to_csv(f\"{BASE_DIR}/price/{symbol_names[k]}.csv\")\n",
    "\n",
    "sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "# processing_image_uri = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, version=\"1.0-1\")\n",
    "script_process = ScriptProcessor(\n",
    "    image_uri=\"555178539686.dkr.ecr.us-east-1.amazonaws.com/stalk-stock-processor:latest\",\n",
    "    command=[\"python3\"],\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=1,\n",
    "    base_job_name=\"script-stalkstock-evaluating\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "\n",
    "step_evaluate = ProcessingStep(\n",
    "    name=\"StalkStockEvaluate\",\n",
    "    processor=script_process,\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"macd\", destination=f\"s3://{s3_evaluate_result_path}/macd/\", source=\"/opt/ml/processing/macd\"),\n",
    "        ProcessingOutput(output_name=\"price\", destination=f\"s3://{s3_evaluate_result_path}/price/\", source=\"/opt/ml/processing/price\")\n",
    "    ],\n",
    "    code=\"stalk-stock/evaluating.py\",\n",
    "    depends_on=[\"StalkStockTrain\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_approval_status' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6e5ba1895804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprocessing_instance_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtraining_instance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mmodel_approval_status\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     ],\n\u001b[1;32m     13\u001b[0m     \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_evaluate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_approval_status' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = f\"StalkStockPipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type, \n",
    "        processing_instance_count,\n",
    "        training_instance_type\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_evaluate],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
